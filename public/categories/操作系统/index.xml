<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>操作系统 on 浙语临湖</title>
    <link>https://jarviszly.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
    <description>Recent content in 操作系统 on 浙语临湖</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 24 Jun 2020 12:06:05 +0800</lastBuildDate>
    
	<atom:link href="https://jarviszly.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>文件系统实现</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Wed, 24 Jun 2020 12:06:05 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/</guid>
      <description>分析  文件系统实现的本质回到了数据结构的设计上。 而数据结构课所学的都是讲的如何在内存上实现出各种数据结构。 内存在多级缓存的帮助下实现了随机访问，并且有多个内存管理的API 而对于磁盘来说，其不能随机访问任意一个bit，而是按照块为单位进行读写，所以每一个bit的访问不是O(1)的，没有malloc等函数的支持，只有read_blk,write_blk. 设计需求：一个树状的结构。 如果只考虑存储文件，一个虚拟磁盘可能对应多个物理磁盘上的块，而这些块不一定是连续的，所以很自然地想到使用链表。 链表有两种方式：  指针和数据放在同一个块中。  优点：不需要额外分配存放指针的空间 缺点: 数据的大小不是2的幂次(因为有一部分是指针)，在lseek的时候就不能使用移位操作来进行。   单独分配几个块存放所有的指针。  优点：局部性好，lseek更快 缺点：集中存放一旦损坏损失大     目录的实现：目录也是一个文件，只不过是在该文件中实现了一个目录的数据结构比如key-value mapping, 通过tag标记让文件系统访问该文件时按照目录的方式。  FAT(File Allocation Table)  采取的是集中存放指针的方法，使用备份的方式来降低损坏造成巨大损失的风险。 在FAT中，将多个块(512B)看作一个cluster，然后以cluster为单位来管理文件。   其中每一个表项  0：未分配 ffffff7: bad cluster(这个cluster损坏) ffffff8-ffffffe,-1：EOF 2&amp;hellip;: 已分配且是下一个块的编号    性能与可靠性  性能  FAT对于小文件来说十分合适 对于大文件来说不理想，因为如果要读取大文件最后一个bit，那么还是得遍历该文件。   可靠性  维护多个备份防止元数据损坏造成额外的开销    ext2/Unix文件系统  和FAT不同的是需要支持链接，所以其树状结构中的节点都是指针。 更关键的是该文件系统提供对大文件的高效的随机访问，设计者在其元数据中使用了类似页表的方式来完成索引。   目录结构：inode编号 + 该项长度 + name长度 + 文件类型 + 4字节对齐的name  性能和可靠性  大文件随机读写性能提高，小文件读写性能同样很好。 但同样和FAT具有存储可靠性的问题。  </description>
    </item>
    
    <item>
      <title>文件系统API</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9Fapi/</link>
      <pubDate>Tue, 23 Jun 2020 22:16:46 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9Fapi/</guid>
      <description>为什么需要文件系统  应用程序直接通过设备驱动程序访问存储设备不合适  多个应用程序并发访问存储设备 一个有Bug的应用程序可能直接损坏整个存储设备。   所以需要在这个基础上再添加一层抽象层，将一个磁盘抽象成多个虚拟磁盘。 文件系统就是对存储设备的虚拟化。  磁盘(I/O设备)是一个可读可写的字节序列 虚拟磁盘是一个动态的可读可写的字节序列   从实现方面来看，文件系统就是在持久化存储设备上的数据结构。  规定了数据的存储方式 提供了对数据结构进行的一些操作    文件API lseek, mmap, ftruncate  mmap  open一个文件后可以使用mmap(MAP_SHARED)将文件映射到地址空间，使用mmap(MAP_PRIVATE)创建一个文件的copy-on-write的副本   问题在于：如果我们使用mmap映射的长度超过文件大小，然后访问了超过文件大小的内容，会发生什么 mmap手册已经说明：会返回一个SIGBUS的信号 ftruncate可以改变一个文件的大小，lseek可以改变读写文件偏移量，那么这三个API可能会相互影响。  比如 mmap 2MB, lseek 3MB, ftruncate 1MB 那么之后读写在哪里？    偏移量管理  从上面一个例子可以知道偏移量管理十分重要。  当进程fork的时候，对于文件描述符是浅拷贝，也就是说父子进程共享一个偏移量。 当使用dup的时候，对于文件描述符也是浅拷贝。 使用open的时候，获得一个独立的offset.    文件系统API-管理众多虚拟磁盘 目录管理  mkdir, rmdir  硬链接和软链接  硬链接  需求：有的时候需要一个文件被多个目录引用，但不像要不必要的拷贝 ln filename newfilename 只允许文件对文件的硬链接，不允许目录的硬链接也不允许跨文件系统的硬链接。 而实际上对于Linux的文件系统来说，其树状结构的每一个叶节点并不是想FAT文件系统一样就是一个文件，而是一个指向某个虚拟磁盘的指针，于是，维护好每个虚拟磁盘的引用计数就能很好地实现硬链接，查看rm的系统调用可以发现使用的是unlink.</description>
    </item>
    
    <item>
      <title>设备驱动</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/</link>
      <pubDate>Tue, 23 Jun 2020 12:07:06 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/</guid>
      <description>I/O设备的抽象  cpu使用指令访问设备寄存器/设备存储。 在此意义上，很多东西都属于I/O设备，比如PIC,总线,DMA等。 而对于应用程序  应用程序具有访问I/O设备有需求 应用程序直接访问I/O设备是不现实的  I/O设备多样，应用程序难以写出portable的代码 不同应用之间需要同步协调各个I/O资源的使用     所以操作系统应该对I/O设备进行一定的抽象。 需求分析  printf: 希望向设备写入一些数据，所以需要write功能 浏览器：希望从某个TCP连接中读取数据，所以需要read功能 &amp;hellip;   所以分析可能需要的API为  read: 读出数据 write: 写入数据 ioctl: 读取/更改设备状态   操作系统建立一个新的抽象层，将不同的I/O设备抽象成为系统中可读可写&amp;hellip;的对象。 这样就能用同一个接口去访问不同的I/O设备，实现接口的代码就是设备驱动程序  设备驱动程序  设备驱动程序就是硬件抽象层的实现。 因为硬件抽象层使得应用程序看不到实际上的I/O设备，所以其实可以创造一些虚拟的，实际上不存在的设备。  如/dev/zero, /dev/null, /dev/urandom   在Linux系统中，everything is a file, 所以其设备驱动也就是文件所需要的一些操作。  特殊的设备-磁盘和网卡  磁盘的特性  以数据块为单位访问 使用DMA传输数据 应用程序一般不会直接访问，而是由文件系统访问。 大量的并发访问   网卡  超高速设备 &amp;hellip;   所以针对这两个设备，linux使用了另外的单独的抽象。  </description>
    </item>
    
    <item>
      <title>信号和jobcontrol</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BF%A1%E5%8F%B7%E5%92%8Cjobcontrol/</link>
      <pubDate>Sun, 21 Jun 2020 20:59:55 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BF%A1%E5%8F%B7%E5%92%8Cjobcontrol/</guid>
      <description>信号机制  想要实现ctrl+c使得进程退出，如何实现？  谁收到了ctrl+c这个东西?  如果在shell中运行一个cat, 然后ctrl+c会发现cat退出  此时shell在wait等待cat执行完返回，所以其不是收到处理ctrl+c的地方 cat此时正在执行read系统调用等待用户的输入，所以也不是。   实际上是操作系统的对象终端，其收到ctrl+c后会给cat进程发送一个SIGINT的信号。那么怎么样实现信号机制，使得无论该进程在干什么，都能被通知。  信号机制的实现  这样的需求可以联想到ICS中提到的硬件的中断机制，将硬件上的中断机制搬到进程上来当作信号机制。 假设cat进程在cpu上运行，当tty收到一个ctrl+c，操作系统会等到该cpu上一个中断到来，此时cat进程的所有信息(寄存器现场，内存)都被保存到了他的栈上实际上也在物理内存中，所以操作系统可以去修改这部分内存，在其间插入跳转到Signal处理的代码去执行，于是该进程就一定能够被通知。 在linux中提供了一些API，比如c语言中的signal可以注册一个处理某个信号的函数，这样就能够捕获到系统中的信号，从而做出不同的行为。  job control  如果一个进程中fork了很多个进程，那么在这个进程执行的时候，如果ctrl+c，那么应该是要所有fork的进程都要退出。 但是，如果这样，那么在shell上执行的所有进程都是通过shell进程fork出来的，那么此时ctrl+c，岂不是所有的进程都被杀死，所以这样简单的设计显然是不够的，应该将这些进程分组管理。 而实际上，在linux系统中，当一个shell启动后就会构成一个session结构，而session结构有一个control terminal和若干进程组。  进程组中的进程具有不同进程号，但是具有相同的进程组号，fork子进程会继承父进程的pgid，而execve不会改变pgid. shell每次fork出新进程都会为其创造一个独立的进程组。 在一个session中，任意时刻，都只能有一个位于前台的进程组。 信号会发送给前台进程组中所有的进程。 man 8 setpgid    </description>
    </item>
    
    <item>
      <title>终端和shell 应用眼中的OS</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BB%88%E7%AB%AF%E5%92%8Cshell-%E5%BA%94%E7%94%A8%E7%9C%BC%E4%B8%AD%E7%9A%84os/</link>
      <pubDate>Fri, 19 Jun 2020 22:05:47 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BB%88%E7%AB%AF%E5%92%8Cshell-%E5%BA%94%E7%94%A8%E7%9C%BC%E4%B8%AD%E7%9A%84os/</guid>
      <description>终端  终端是操作系统中的一个对象,也是一个I/O设备。 在Unix看来，终端也是一个文件(everything is a file)  ANSI Escape Codes  终端支持Escape Codes，通过这些Codes可以完成屏幕清除/滚动，设置颜色等。 如果用cat输出某些二进制文件之后，可能会发生一些神奇的事情，比如光标没了之类的，这是因为可能该二进制文件中正好有一个负责控制光标的Escape Code，然后其在终端中输入就执行了。 可以用reset来还原终端  终端的模式  默认是cooked mode, 也就是终端自带一个行编辑器，按下回车才去执行这一行的命令 还有一个raw mode，按键就返回。  向终端输出  使用ls &amp;ndash;color等变体发现  ls &amp;ndash;color : 显示颜色，输出在一行 ls &amp;ndash;color | less : 不显示颜色(只显示ESC序列)并在多行输出。   那么发生了为什么？ 使用strace 和 lstrace 康康不同层面干了什么吧 查看ltrace可以发现，都调用了一个isatty()函数，用来判断标准输出是不是终端，然后自适应输出。 查看strace可以发现isatty()会调用一个系统调用ioctl().  Shell  操作系统 = 对象 + API, 那么用户怎么调用API? shell是一门编程语言.  interactive shell: 收到一行执行一行  env | grep PS1   non-interactive shell: 就是普通的语言解释器  bash -c &amp;lsquo;env&amp;rsquo; | grep PS1     shell是人机接口,interactive shell将用户给I/O设备的指令翻译成了系统调用的序列, 也就是说shell是用户眼中的操作系统(I/O设备)和应用眼中的操作系统(syscall)的桥梁。 shell正如其名，它是操作系统内核对外的一个外壳，外界将需要传达的shell，shell则翻译成一系列系统调用然后传达给内核。 shell的分类：CLI/GUI  shell的实现  shell的实现中有两个最基本的功能：向操作系统的某个对象读和写，比如cat命令，通过strace可以发现调用了read和write两个系统调用，这两个系统调用都是向文件描述符里读或写，那么什么是文件描述符 文件描述符： 是一个指向操作系统中某个对象的指针，是进程(状态机)的一部分，所以在fork的时候也会被拷贝。  shell中的重定向 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  echo Hello World &amp;gt; a.</description>
    </item>
    
    <item>
      <title>DemandPaging</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/demandpaging/</link>
      <pubDate>Wed, 17 Jun 2020 11:04:30 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/demandpaging/</guid>
      <description>Demand Paging(按需求分配页面)  mmap实际上只是做了一些标记，并没有实际上的分配物理内存，所以mmap的速度很快。 实际上，在execve重置进程的时候，此时只需要  在物理内存中分配一个页面给该进程的cr3. 修改进程对应的映射函数或者说映射数据结构(cr3), 使得进程虚拟地址空间中的内核代码和物理内存中的os代码建立映射。 在操作系统的数据中必然存在一个数据结构来表示该进程，如下 1 2 3 4 5 6 7 8 9  struct mm_area{ _Area range; //内存映射的区间  int prot, flags, fd, offset;//映射的属性  struct page* pages; //用于遍历该映射中所有的页面。 } struct task{ struct mm_area areas[16]; ... }   只需要在加载时设置好这些$mm_area$,就可以。
 然后将$rip$置为$ELF~entry$(静态链接)或者 $lib.so$(动态链接)执行即可。 当发生缺页情况或者dereference nullptr时，cr2寄存器中会保留发生异常的地址，然后根据这些信息到$tas$k的$mm_area$去查询有没有匹配的，如果没有匹配则出现异常，否则根据$mm_area$中信息从磁盘中读取数据到物理内存中。    Swap  Demand paging的另一个用途就是其反方向。 一个进程已经分配了页面，但我们可以主动将该页面swap out,保存到磁盘中，然后使用原来该页面的物理内存，当又需要该部分数据时，又swap in. LRU是较好的Swap策略。  Shared Objects 和 外部符号   动态链接库采用GOT表格，而如果修改对应的GOT表项，比如将printf对应的表项的地址改为自己写的printf_wrapper的地址，那么当我们调用printf时就会去执行printf_wrapper，而我们在printf_wrapper中同样可以去调用printf函数，并且在之前打印一些log，这样我们就得到了ltrace</description>
    </item>
    
    <item>
      <title>处理器调度</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/</link>
      <pubDate>Tue, 16 Jun 2020 14:19:05 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/</guid>
      <description>单处理器分时调度 Round-Robin调度方法  将时间划分成一个个时间片，每个进程轮流获取一个时间片的CPU。 但是不同进程对cpu的需求是不一样的，一个极端的例子就是10个进程，有9个是死循环，还有一个vim进程，如果此时使用Round-Robin算法，则会导致vim进程获取输入缓慢，所以我们需要给不同进程设置优先级。  优先级  Unix nicess  nice属性的值的范围在-20~19，其中-20意味着极坏，19意味着极好，越坏的进程越容易获得cpu。   如果使用Round-Robin的形式，如何划分优先级  在圆上根据nice值，按照一定比例划分进程对应的圆弧，然后一个指针在圆上旋转，指针指到哪个进程部分，就执行哪个进程。    多级反馈调度  在系统中存在多个Round-Robin调度器，每个调度器对应一个优先级，优先级高的先调度，只有优先级高的都暂时不需要cpu时，才可以调度低优先级的。  Linux调度器-CFS(完全公平调度)  每个进程都有一个vruntime属性记录该进程到目前为止在cpu上的虚拟运行时间，每次需要切换进程时都选择补偿虚拟运行时间最短的那个。 如果一个进程创建子进程，则其子进程会继承父进程的vruntime  一些小问题  问题1：如果一个进程沉睡了较长时间，那么被唤醒后一段长时间都是该进程占据cpu 解决办法：唤醒进程时给进程的$vruntime = max(vruntime, min(vruntime_{others}))$,这样就能保证其既能很快获得调度又不会长时间占据cpu。 问题2：优先级如何表示 解决办法：进程的vruntime实际上就是根据优先级来使用不同权重计算的，对于坏的进程，可能其一个vruntime就能获得多个时间片，而对于好的进程，可能一个vruntime只能获得1个或少量的时间片。 问题3：用什么数据结构实现vruntime 解决办法：linux中复用了红黑树。 问题四：用64位无符号整数表示vruntime,其运行500多年会发生溢出问题，如何解决 解决办法：Linux内部使用的是两个vruntime之间的$\Delta$来确定两个进程谁应该被调度。  其假设不会有进程沉睡很长很长时间，所以系统中的所有进程的vruntime相差不会很大(假设不会超过u64的一半)。 1 2 3 4 5 6 7 8  s64 delta = (s64)(a-&amp;gt;vruntime - b-&amp;gt;vruntime); //如果delta &amp;lt; 0, 则说明应该调度a. //否则应该调度b.  /* 如果a溢出了那么在数值上a-&amp;gt;vruntime远小于 * b-&amp;gt;vruntime，但是两者的差转换为带符号64位整 * 数后就会变为正数。 */       优先级翻转   实际上当考虑到互斥同步的情况后，会给某些调度方法带来一些问题：</description>
    </item>
    
    <item>
      <title>动态链接</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/</link>
      <pubDate>Mon, 15 Jun 2020 23:05:37 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/</guid>
      <description>静态链接  为了一个程序不同部分的解耦，可以将一个程序分成若干个文件是十分必要的，那么不同的文件最终怎么变成一个可执行文件加载到操作系统上执行的。  1 2 3 4 5 6 7 8 9 10 11 12 13 14  //a.c int foo(int a, int b){ return a + b; } //b.c int x = 100, y = 200; //main.c extern int x,y; int foo(int a,int b); int main(){ printf(&amp;#34;%d + %d = %d\n&amp;#34;,x,y,foo(x,y)); }     不同的文件通过编译形成不同的$.o$文件，查看$main.o$可以发现，其对$x,y,foo$的使用，都使用$0(%rip)$代替($rip$寻址，但偏移量不知)。
  在静态链接的之后，就会根据ELF文件头信息，正确地填入偏移量，ELF文件中都是符号地址-4，是因为此时rip指向的是下一条指令，其相对于所需填入的地方增加了4个字节($0(%rip)$中的0占4字节)。
  静态ELF加载器：
 在加载静态链接得到的可执行文件时，直接根据ELF程序头表中信息使用mmap将文件中对应部分映射到地址空间中即可。    动态链接  如果都是用静态链接太耗费资源。  需求1  所需动态链接的库只含有代码。 实现：直接使用mmap将这部分映射到对应程序的地址空间，这样也保证了在物理内存中只有一个该库函数的备份。 实现前提：代码需要是位置无关代码，引用跳转使用(PC相对寻址)。  需求2  所需动态链接的库含有本库使用的代码和数据。 实现：同样只需要mmap，因为数据也可以根据数据和PC的Offset来相对寻址。  需求3  在一个动态链接库中可以使用其他动态链接库的符号。 实现：使用表来记录相应的函数的地址。比如在foo中调用bar，动态链接器先加载bar所在的库，然后加载foo时，就将bar所在的地址填入表格中。  Linux中的动态链接-GOT和PLT   linux中动态链接同样使用了需求3类似的理念，用表格来记录地址，一个程序有一个GOT表，其结构如下：</description>
    </item>
    
    <item>
      <title>进程抽象</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E6%8A%BD%E8%B1%A1/</link>
      <pubDate>Mon, 15 Jun 2020 12:30:41 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E6%8A%BD%E8%B1%A1/</guid>
      <description>回顾操作系统   在应用程序看来操作系统就是一组系统调用。
  在底层硬件看来操作系统就是一个C程序，一个状态机。
  操作系统是对进程状态机的模拟，这种模拟就是所谓的虚拟化，进程认为自己独占cpu。
  操作系统中常见API
 进程(状态机)管理  fork: 拷贝一份当前的进程(包括内存，寄存器现场，操作系统的对象，libc中缓冲区等等)。 execve: 替换当前进程为另一个进程，从头执行。 exit: 退出当前进程。   存储(地址空间)管理  mmap: 地址空间和物理内存之间的映射。 brk: 虚拟地址空间管理   文件(数据对象)管理  open,close: 文件访问管理 read,write: 数据管理 mkdir, link, unlink: 目录管理      进程抽象-fork,execve,exit fork  复制一个一摸一样的进程出来，一个返回子进程pid，子进程则返回0。  1 2 3 4 5 6  #define N 2 for(int i = 0; i &amp;lt; N; ++i){ fork(); printf(&amp;#34;hello,world.</description>
    </item>
    
    <item>
      <title>虚存,Linux进程地址空间</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E5%AD%98linux%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Thu, 11 Jun 2020 22:51:05 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E5%AD%98linux%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/</guid>
      <description>Linux进程的地址空间  进程的地址空间如何创建，创建之后如何修改？  1 2 3 4 5 6 7  //映射 void* mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); int munmap(void *addr, size_t length); //修改映射权限 int mprotect(void *addr, size_t length, int prot);     看mmap手册可以知道其作用是可以将某个文件中的一部分映射到内存中一部分，所以很容易可以想到在进程地址空间创建时，需要将进程的代码和数据搬到地址空间，所以可以用mmap来当作加载器。
  那么mmap又是如何实现的，通过strace观察mmap可以发现，其使用了/proc/proc_id/maps文件中的信息，这个文件中记录了该进程的所有内容在文件和地址空间间的映射关系。
  通过cat查看/proc/proc_id/maps的内容，可以发现进程的地址空间为
     动态链接库在heap和stack之间
  而在地址空间最后三个部分，发现了三个神秘的东西(vvar,vdso,vsyscall)
 vvar: 内核和进程共享的数据 vdso: 系统调用的代码实现，这些系统调用不需要陷入内核执行。(比如time，getcpu等) vsyscall: 以前的系统调用的代码实现，但因为安全问题，已经不再使用，为了向后兼容而保留。    虚拟存储-分页机制  为了实现mmap这样的映射机制，硬件给予的支持就是虚拟存储-分页机制。 而分页机制最本质的问题就是找一个合适的数据结构来表示虚拟地址到物理地址的映射关系，已经将虚拟地址和物理地址以页为单位划分，则需要表示$2^{20}$到$2^{20}$的映射关系。 使用数组是第一个很直观的想法，但是数组开销太大，无法忍受。 使用radix-tree(基数树)  在32位机器中，设定一页为4KB，一个指针为4B，所以一页可以存放1024个指针，所以一页可以表示10位，每一个指针又指向这样一个页面，于是两级表示了20位，在第二级结点中，每个指针直接指向一个实际的页面，于是总共表示了32位。 在64位机器中，用了4级表示了48位，实际上64位机器其物理地址为48位。    </description>
    </item>
    
    <item>
      <title>同步{条件变量，信号量，生产者消费者问题，哲学家吃饭问题}</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%90%83%E9%A5%AD%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 09 Jun 2020 22:29:06 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%90%8C%E6%AD%A5%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%90%83%E9%A5%AD%E9%97%AE%E9%A2%98/</guid>
      <description>同步  两个(或多个)线程在一定时间内保持一定的关联。 直白的来说：  互斥：各个线程单独完成自己的事情。 同步：多个线程协作完成一件事情，所以在某些时候线程之间需要知道彼此的状态。    实现同步 条件变量(极其重要)  同步的本质: 当一个条件满足时，线程继续执行，否则等待。 则用一个条件变量(对象)对应表示该条件。  当条件不满足时，在该对象处等待。 当一个线程发现某个条件满足时，唤醒该条件变量对应的线程(一个或者所有)   条件变量API  1 2 3  wait(&amp;amp;cv); //在cv条件变量处等在。 signal(&amp;amp;cv)/notify(&amp;amp;cv); //唤醒一个cv条件变量对应线程。 broadcast(&amp;amp;cv)/notifyall(&amp;amp;cv); //唤醒cv条件变量对应的所有线程。    在使用条件变量时，常常需要使用某个变量来表示条件，而该变量是所有线程共享的，所以在访问时需要使用锁(互斥锁)来保护，所以条件变量搭配互斥锁一起完成同步  1 2 3 4 5 6 7  mutex_lock(&amp;amp;mutex); // do some things wait(&amp;amp;cv,&amp;amp;mutex); //在wait中会先释放掉该互斥锁，再等待，被唤醒时会先尝试重新获得该互斥锁。 // do some things mutex_unlock(&amp;amp;mutex); //signal不需要用mutexlock保护    需要注意的是使用条件变量是一定一个条件对应一个条件变量。  信号量  信号量 = 带计数条件变量(相当于条件变量和控制条件的变量综合) + 互斥锁。 通俗理解：将信号量看作更衣室的手环，拿到手环才可以进入更衣室否则等待。 当手环数量为1时，信号量的作用和互斥锁一致。 信号量API  1 2  P(&amp;amp;semv); //申请一个手环，如果拿到就返回否则等待。 V(&amp;amp;semv); //用户生成一个手环，交给等待用户或者管理者。   经典同步问题 生产者消费者问题   问题描述：</description>
    </item>
    
    <item>
      <title>并发数据结构malloc Free算法</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%B9%B6%E5%8F%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84malloc-free%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sat, 30 May 2020 21:37:09 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%B9%B6%E5%8F%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84malloc-free%E7%AE%97%E6%B3%95/</guid>
      <description>并发数据结构-并发链表  在要使用很多次链表的场合，定义链表头时应该直接定义为一个链表结点，而不是一个指针。  当链表头是一个指针时，在操作时就需要考虑指针是否为空的情况。 当链表头是一个结点时，就不需要考虑这个情况，此时链表头不存储任何数据 。    </description>
    </item>
    
    <item>
      <title>操作系统中的互斥</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E4%BA%92%E6%96%A5/</link>
      <pubDate>Sat, 30 May 2020 20:56:25 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E4%BA%92%E6%96%A5/</guid>
      <description>操作系统上的互斥(多处理器多线程) 1 2 3 4 5 6 7  void func(void* arg){ while(1){ lock(&amp;amp;biglock); printf(&amp;#34;Thread-%s on CPU #%d acuquired the lock\n&amp;#34;,arg,_cpu()); unlock(&amp;amp;biglock); } }    上述代码在多处理器上多线程运行时会发现一段时间后，总是一个线程在一个处理器上获得锁。safety和liveness都没问题而,fairness出现了问题。 使用状态机来理解发现：对于持有了锁的线程，其中断大概率出现在printf，而此时其他CPU上的其他线程都处于自旋状态，结果绕一圈回到自己继续执行。 这说明：获得自选锁的线程(处理器)不应该被中断，否则会因为其他线程的自旋浪费时间，所以可以在lock函数中加入关中断，在unlock中加入开中断  1 2 3 4 5 6 7 8 9  void spin_lock(spinlock_t &amp;amp;lk){ cli(); while(atomic_xchg(&amp;amp;lk-&amp;gt;locked,1)); } void spin_unlock(spinlock_t &amp;amp;lk){ atomic_xchg(&amp;amp;lk-&amp;gt;locked,0); sti(); }    而上述代码又面临一个问题，如果一个线程多次获得不同的锁，之后又依次释放锁，则结果第一次释放锁就导致开中断，因此需要保存第一次获得锁的时候线程(CPU)中断状态，在最后一次释放锁的时候还原状态。 所以需要在CPU的结构中加上记录当前CPU关中断计数以及首次关中断时 %eflags &amp;amp; FL_IF的值  互斥锁  自旋锁由于可能导致浪费很多资源，所以其只适用于很短并且希望能立即执行的临界区。而有的时候，只有互斥的需求但不介意被打断或者自身等待。 比如在读写磁盘时，此时如果使用自旋锁，会导致浪费很多时间，并且在这段时间内可能有很多中断，但由于关中断的原因无法到达CPU. 互斥锁的需求分析  持有锁的线程  允许处理器相应中断。 允许切换到其他线程。   等待锁的线程  不要占用处理器资源自旋。     一个很简单的想法就是当我发现自身无法得到锁，需要自旋时就让另一个线程执行。  1 2 3 4 5  void mutex_lock(mutexlock_t &amp;amp;lk){ while(atomic_xchg(&amp;amp;lk-&amp;gt;locked, 1)){ let_another_thread_to_execute(); } }    上述方法值得优化的点在于：可能等待锁的线程有很多，前面需要空转很多线程(每个线程都会atomic_xchg)才能让真正可以执行的线程执行。 所以可以加上一个调度者，每当线程无法获得锁时就直接放弃对CPU的占有，陷入等待，等待调度者的调度。 添加一个等待队列这样的并发数据结构，由调度者控制  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  void mutex_lock(mutexlock_t &amp;amp;lk){ int acquired = 0; spin_lock(&amp;amp;lk-&amp;gt;spinlock);//保护等待队列  if(lk-&amp;gt;locked !</description>
    </item>
    
    <item>
      <title>硬件初始化与操作系统加载</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A1%AC%E4%BB%B6%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8A%A0%E8%BD%BD/</link>
      <pubDate>Wed, 20 May 2020 21:52:55 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A1%AC%E4%BB%B6%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8A%A0%E8%BD%BD/</guid>
      <description>硬件初始化   硬件和软件之前存在一定的约束
 CPU reset后其处于一个确定的状态，其PC指针一般指向一段ROM,而这个ROM中存储了硬件厂商提供了firmware(固件) 此时处理器大部分特性都是关闭的比如缓存，虚存    Firmware(BIOS, UEFI)
 将用户数据加载到内存  存储介质上的二级loader(比如x86) 直接加载操作系统(嵌入式系统)      Legacy BIOS的约定
 会把引导盘的第一个扇区(512B)加载到内存，然后跳转到这部分执行    操作系统的加载   BIOS加载的512字节中包含了
 16bit $\rightarrow$ 32bit ELF32/64的通用loader    执行完16位向32位的转换后，会跳转到通用loader上执行，该通用loader默认引导盘的存储形式为    所以该loader会先将main函数的参数加载到内存，然后接着加载剩余ELF文件的第一页(4KB),然后根据第一页中ELF文件头的信息，加载剩余所需要的部分，完成ELF文件加载，就跳转到该ELF文件的入口处执行
  ELF文件开始就是从32位模式，转为64位模式，然后建立页表，设置段寄存器，完成初始化，跳转执行。
  跳转执行后，会完成很多cpu的初始化，然后切换堆栈，跳转去执行main.
  </description>
    </item>
    
    <item>
      <title>线程的互斥</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BA%92%E6%96%A5/</link>
      <pubDate>Sat, 16 May 2020 23:23:18 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BA%92%E6%96%A5/</guid>
      <description>在现代处理器上Peterson算法的问题  Peterson算法中的，x = 1; turn = T2; 在处理器上会变成指令store(x, 1) store(turn, T2).而因为store指令都比较耗费时间，所以在现代处理器的优化下，处理器会指令后面的指令从而导致两个线程都进入临界区。 很大的问题在于在计算机世界中，我们无法同时&amp;quot;看&amp;quot;和&amp;quot;做&amp;quot;即不能同时load 和 store.  共享内存带来更多的问题  由于不能同时load和store所以当线程共享内存时，会引发其他问题，比如多线程求sum. 四个线程求和放入同一个变量，加法对应的指令只有一条add，如果按照状态机的假设，每次只执行一条指令且指令是原子性的，那么答案应该正确。 而实际上，一条add指令可以被看成三条更小的指令：load, ++, store.而这三条指令之间的原子性等没有得到保证，所以出现错误。  x86的解决方法-增加原子性操作  x86架构提供了一些原子性操作来使得软件能够完成锁的实现，比如 lock add(一条原子性的add指令)，xchg(一条原子性的交换内存和变量的值的指令)等。 使用xchg指令可以很简单地实现自旋锁  1 2 3 4 5 6 7 8 9  int table = key; void lock(){ while(1){ int got = xchg(&amp;amp;table,NOTE); if(got == key) break; } } void unlock(){ xchg(&amp;amp;table,key);   RISC-V和Mips的解决办法-提供满足原子性的load和store  LoadReserved/Store-Conditional(LR/SC)  LR: 正常的读取某一个变量，并在相应变量上标记哪个线程所标记。 SC: 储存之前，检查标记是否对应，如果对应则正常存储，否则重做之前的指令。   LR/SC  实际上就是当LR和SC之间的操作都没有被破坏原子性等，自然这些指令就保证了原子性。  数据竞争  并不是加上了锁就能保证多线程的正确运行，比如两个线程用两把锁对同一个变量修改。 实质是 当有两个线程有两个操作访问同一段内存，且这两个操作之间没有原子性的指令(也就是不能保证两个操作执行的顺序)，就会出现数据竞争。 解决办法：对于多线程共享的内存用同一把锁。  </description>
    </item>
    
    <item>
      <title>状态机模型理解程序执行</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%8A%B6%E6%80%81%E6%9C%BA%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/</link>
      <pubDate>Thu, 14 May 2020 20:30:58 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%8A%B6%E6%80%81%E6%9C%BA%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/</guid>
      <description>单线程程序的状态机模型  不同内存和寄存器状态对应了状态机的不同节点。 大部分状态s有唯一的后继状态，存在一些指令，其有后续状态，如rdtsc(获取处理器时间戳)，rdrand(真随机数),syscall(系统调用) 状态机模型是一种理解程序和分析程序的工具  模型的应用 Time travel debugging  程序运行都是从初始结点向后跳转，那么能否从前往后？ 如果能把状态全部记下来是不合理的，但是一条指令只改变很少的寄存器和内存，所以只需要记录两个状态之间的diff就行。 gdb  target record-full 开始记录(此是需要程序已经开始执行) record stop 结束记录 reverse-step(rs)/reverse-stepi(rsi) 向前跳转    Record and Replay  记录程序执行的信息，重现某次程序执行结果。 对于确定性的指令，只需要记录下开始位置和执行了多少条指令。 对于不确定性的指令，则需要记录额外的信息，比如read系统调用，需要记录read的返回值，其读入的具体数据等。  多线程(并发)程序的状态机模型  确定了每一个线程的寄存器状态和共享内存的状态就唯一确定了一个状态机状态，多线程程序的状态机模型本身一个状态的后继状态就是多样的。 因为多线程状态机状态太多了，所以之前的应用需要重新设计。  Peterson算法：实现2个线程的互斥  两个人(P1,P2)分别有一个棋子(F1,F2)并分别可以向卫生间门上的板子上写上对方的名字。 代码如下  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //假设及其每次原子地执行每一行代码，内存访问立即可见 int f1 = 0, f2 = 0;//棋子 int turn = P1;//厕所上的牌子 void thread_1(){ f1 = 1;//举起自己的棋子  turn = P2;//优先让别人先去  while(f2 &amp;amp;&amp;amp; turn == P2); //对方举了棋子并且还未去  //临界区  f1 = 0;//放下棋子 } void thread_2(){ f2 = 1; turn = P1; while(f1 &amp;amp;&amp;amp; turn == P1); f2 = 0; }    可以枚举出这两个线程执行顺序的所有可能来证明该算法的正确性。  </description>
    </item>
    
    <item>
      <title>并发编程</title>
      <link>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Sun, 10 May 2020 21:48:04 +0800</pubDate>
      
      <guid>https://jarviszly.com/documents/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</guid>
      <description>并发编程 并发和并行  并发(Concurrent): 多个执行流可以不按照一定的顺序执行 并行(Parallel): 多个执行流可以同时执行(多个处理器)  线程共享  线程之间共享所有代码和全局变量。 每个线程拥有自己的堆栈，独享寄存器。  C语言多线程编程之入门  POSIX Threads, man 7 pthreads, 需要gcc -lpthread gcc -I 选项增加include path(效果等价于 #include &amp;ldquo;&amp;quot;)  多线程编程之放弃 放弃原子性  由于 中断/异常 的机制，导致一个线程的代码(指令)不会按照其顺序执行。 例子：山寨支付宝(有钱人的生活就是这般枯燥无味)  1 2 3 4 5 6 7 8 9  int money bool pay(int cost){ if(money &amp;gt;= cost){ money -= cost; return true; } else return false; }   放弃顺序性  由于 编译器的优化 指令的顺序可能和程序的顺序不一致。 例子：不同优化等级的for循环累加  1 2 3 4  #define n 100000int sum = 0; for(int i = 0; i &amp;lt; n; ++i) sum++;    可以使用objdump -d 查看不同优化等级下的汇编代码。  放弃可见性  由于 CPU 的加速，导致指令不一定按照其显示的顺序执行。 例子：两个线程分别对x，y赋值并打印  1 2 3 4 5 6 7 8 9 10 11  int x = 0, y = 0; void thread_1(){ [1] x = 1; [2] printf(&amp;#34;y = %d\n&amp;#34;,y); } void thread_2(){ [3] y = 1; [4] printf(&amp;#34;x = %d\n&amp;#34;,x); }      x y 概率 调度顺序     0 0 0.</description>
    </item>
    
  </channel>
</rss>