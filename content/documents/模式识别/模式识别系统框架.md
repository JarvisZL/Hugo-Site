---
author: "Lingyu Zhang"
author_link: "https://jarviszly.com"
title: "模式识别系统框架"
date: 2020-03-05T09:04:58+08:00
lastmod: 2020-03-05T09:04:58+08:00
draft: false
description: ""
show_in_homepage: true
description_as_summary: false
license: ""

tags: [模式识别]
categories: [模式识别]

featured_image: ""
featured_image_preview: ""

comment: true
toc: true
auto_collapse_toc: true
math: true
---
# 最近邻和模式识别系统框架及其个模块简介
<!--more-->

## 最近邻规则

### 问题设置
- 分类问题
  - 训练集$D =$ \{ $(x_1,y_1),\cdots,(x_n,y_n)$ \}
  - 训练样本：$x_i \in X \subseteq R^d$
  - 样本标记：$y_i \in y =$\{$1,2,\cdots,C$\}    
- 存在一个距离函数$d(x,y)\in R$：能够度量x，y之间的不相似程度


### 最近邻规则和Voronoi图
- 给定一个测试样例$x$
  - 发现其最近邻$i^* = \mathop{argmin}\limits_i~ d(x,x_i)$, $argmin$返回$d$最小的index value
  - 输入对$x$的分类的预测：$y_{i^*}$
  - ![](/images/documents/模式识别/Voronoi.png)
  - 如果落到了某个区域，就取该区域中的那个点代表的结果

### 最近邻可能出现的问题
- 出现平局：$d(x,x_i) = d(x,x_j)$
- 出现离群点怎么办(最近的那个标记有问题)：
  - K-近邻规则(KNN)
- 当训练样本<font color=red size=3>趋近无穷</font>时，最近邻的错误率最多是<font color=red size=3>最佳错误率的两倍</font>

### 计算，存储代价
- 假设$d(x,y)$时欧式距离
  - 其复杂度时$O(d)$
  - NN的复杂度$O(nd)$
  - KNN的复杂度同样是$O(nd)$: $O(nd)+O(n)+O(k)$通常k很小可以忽略，而$O(n)$是用于从n个数中选择k个最小的

### 降低NN计算和存储代价
- 近似最近邻(ANN)
  - 不一定是距离最短的k个
  - 如第k个NN，其距离是$d_k$则ANN要求选取的所有k个样例的距离$\hat{d}$满足$\hat{d} \leq (1+\epsilon)d_k$
- 二值哈希

## 系统各模块(混合)简介

### 细化(refined)的框架
- 机器学习$f: x \rightarrow y$
  - 与领域无关的特征变换和特征抽取：Normalization,PCA,FLD
- 针对不同数据特点的不同学习方法

## 模型评价评估

### 评价准则-泛化和测试误差
- 暂时只考虑分类问题的评价
- 假设$(x,y)\thicksim p(x,y)$
  - 泛化误差：$E_{(x,y)\thicksim p(x,y)}[f(x)\neq y]$,通常无法实际计算
  - 根本假设：训练集$D_{train}$和测试集$D_{test}$都服从真实数据分布$p(x)$，通常独立同分布
  - 测试误差($\mathbb{I}$表示指示函数)
    $$err = \dfrac{1}{n}\sum_{i=1}^n \mathbb{I}(f(x_i) \neq y_i) \qquad x_i \in D_{test}$$
  - 精确度：$acc = 1-err$


### 一种常见的学习框架
- 代价最小化：学习目标是在训练集上获得最小的代价
- $\mathop{min}\limits_f \dfrac{1}{n} \sum_{i=1}^n \mathbb{I}(f(x_i)\neq y_i) \qquad x_i\in D_{train}$
- 指示函数难以优化：一种方法是把不连续的指示函数换成性质相似但是好优化的函数如$(f(x_i)-y_i)^2$

### 过拟合和欠拟合
- 学习模型的复杂性小于数据的复杂性：欠拟合
- 学习模型的复杂性大于数据的复杂性：过拟合
  - 可能在训练集上拟合非常好，但在以外的地方特别差
- 通常难以精确估计学习模型，数据的复杂性
  - 往往选用较为复杂的学习模型
  - 使用<font color=red size=3>正则化</font>来降低过拟合的可能性

### 如果没有测试集
- 交叉验证
  - 将训练集分成大小大致相等的N部分-
  - for i = 1:N
    - 取第i部分的数据为测试集
    - 取其余部分数据为训练集
    - 学习模型并评估测试得到的错误率$err_i$
  - 交叉验证得到的错误率为$\dfrac{1}{N} \sum_{i=1}^N err_i$
  - 称为N倍交叉验证

### 数据，代价的不平衡性(imbalance)
- 如两类问题中，一类数据远比另一类数据多,比如体检中阴性和阳性。
- 或者在一类犯错的代价远高于另一类，如癌症筛查。

### 评价不平衡时的准则

![](/images/documents/模式识别/评价不平衡准则.png)
- 总数: $TOTAL = TP+TN+FP+FN$, 正样本数目：$P = TP + FN$, 负样本数目: $N = FP + TN$
- False Positive rate: $FPR = \dfrac{FP}{\textcolor{red}{N}}$, False negative rate: $FNR = \dfrac{FN}{\textcolor{red}{P}}$, True positive rate: $TPR = \dfrac{TP}{\textcolor{red}{P}}$, True negative rate :$TNR = \dfrac{TN}{\textcolor{red}{N}}$(考虑什么的比例，什么就是分子，而分母为正确值的数目)
- 准确率: $ACC = \dfrac{(TP+TN)}{TOTAL}$

#### AUC-ROC(Area Under the ROC Curve)
- ROC: Receiver operating characteristic.
- Y轴：TPR，X轴：FPR
<img src="/images/documents/模式识别/AUC-ROC.png" style="zoom:  60%">
- 曲线单调
- 对角线为完全随机的情况，我们希望TPR更大一些，所以我们得到的曲线应该要不比对角线低，概率应该大于0.5(面积)

#### 适合检索(retrival)的准则
- 查准率(Precision): $PRE = \dfrac{TP}{(TP+FP)}$，查全率(Recall)：$REC = \dfrac{TP}{P}$
- F1 score:Precision和Recall的调和平均(harmonic mean)
  - $(\dfrac{x^{-1}+y^{-1}}{2})^{-1} = \dfrac{2xy}{x+y}$
  - $F1 = \dfrac{2TP}{(2TP+FP+FN)}$

#### AUC-PR(Area Under the Precision-Recall Curve)
- <img src="/images/documents/模式识别/AUC-PR.png" style="zoom:  60%">
- 曲线非单调，其比AUC-ROC更有区分能力

### 代价矩阵
- 目前常见的为$\begin{bmatrix} \lambda_{11} & \lambda_{12}\\\\ \lambda_{21} & \lambda_{22}\end{bmatrix} = \begin{bmatrix}0 & 1\\\\ 1 & 0 \end{bmatrix}$
  - $\lambda_{ij}$：当真实值为i，模型预测为j时付的代价
  - 0-1代价：即分类正确代价为0，分类错误代价为1
  - 根据实际情况，代价可以为任何值
- 对代价的计算$E_{(x,y)}[\lambda_y,f(x)]$
  - 当使用0-1代价时，和错误率一致。